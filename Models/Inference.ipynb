{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T15:25:32.636021Z","iopub.execute_input":"2023-12-28T15:25:32.636459Z","iopub.status.idle":"2023-12-28T15:25:32.642834Z","shell.execute_reply.started":"2023-12-28T15:25:32.636427Z","shell.execute_reply":"2023-12-28T15:25:32.641495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip -q install gdown","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:25:32.653572Z","iopub.execute_input":"2023-12-28T15:25:32.654487Z","iopub.status.idle":"2023-12-28T15:25:49.822569Z","shell.execute_reply.started":"2023-12-28T15:25:32.654441Z","shell.execute_reply":"2023-12-28T15:25:49.821442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:25:49.824534Z","iopub.execute_input":"2023-12-28T15:25:49.824909Z","iopub.status.idle":"2023-12-28T15:25:52.072971Z","shell.execute_reply.started":"2023-12-28T15:25:49.824876Z","shell.execute_reply":"2023-12-28T15:25:52.071532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('output_cleans.csv')\ndf = df[df['lang']=='en']","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:25:52.075114Z","iopub.execute_input":"2023-12-28T15:25:52.075724Z","iopub.status.idle":"2023-12-28T15:25:52.912500Z","shell.execute_reply.started":"2023-12-28T15:25:52.075672Z","shell.execute_reply":"2023-12-28T15:25:52.911113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:25:52.916389Z","iopub.execute_input":"2023-12-28T15:25:52.917252Z","iopub.status.idle":"2023-12-28T15:26:07.621161Z","shell.execute_reply.started":"2023-12-28T15:25:52.917210Z","shell.execute_reply":"2023-12-28T15:26:07.619542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" !pip install -q --no-cache-dir transformers sentencepiece","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:26:07.623076Z","iopub.execute_input":"2023-12-28T15:26:07.623845Z","iopub.status.idle":"2023-12-28T15:26:22.751261Z","shell.execute_reply.started":"2023-12-28T15:26:07.623806Z","shell.execute_reply":"2023-12-28T15:26:22.749683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"rawContent\"] = df[\"rawContent\"].dropna()\ndf.dropna(subset=['rawContent'], how='any', inplace=True)\n# df = df[20000:50000]","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:26:22.753146Z","iopub.execute_input":"2023-12-28T15:26:22.753551Z","iopub.status.idle":"2023-12-28T15:26:22.831887Z","shell.execute_reply.started":"2023-12-28T15:26:22.753513Z","shell.execute_reply":"2023-12-28T15:26:22.830678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_metric\nimport pandas as pd\n\n# Load the model and tokenizer\nmodel_name = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\nfrom tqdm import tqdm\ntqdm.pandas()\n\n# Define the sentiment labels\nlabels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n\n\ndef predict_sentiment(text):\n    \"\"\"\n    \"\"\"\n    encoded_input = tokenizer(text,  truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n    output = model(**encoded_input)\n    predictions = output.logits.argmax(-1)\n    return labels[predictions.item()]\n\ndf[\"sentiment\"] = df[\"rawContent\"].progress_apply(predict_sentiment)\n\ndf.to_csv(\"tweet_sentiment.csv\", index=False)\n\nprint(\"Sentiment analysis completed!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T07:10:13.303990Z","iopub.execute_input":"2023-12-28T07:10:13.304670Z","iopub.status.idle":"2023-12-28T07:10:21.816555Z","shell.execute_reply.started":"2023-12-28T07:10:13.304636Z","shell.execute_reply":"2023-12-28T07:10:21.814327Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_metric\nimport pandas as pd\nfrom transformers import pipeline\n\n# Load the model and tokenizer\nmodel_name = f\"skandavivek2/spam-classifier\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\nfrom tqdm import tqdm\ntqdm.pandas()\npipe = pipeline(\"text-classification\", model=\"skandavivek2/spam-classifier\")\n\nlabels = {0: \"Not spam\", 1: \"Spam\"}\n\n# Define the function for sentiment analysis\ndef predict_spam(text):\n    \"\"\"\n    Predicts the sentiment of a tweet using the model.\n    \"\"\"\n    encoded_input = tokenizer(text,  truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n    output = model(**encoded_input)\n    predictions = output.logits.argmax(-1)\n    return labels[predictions.item()]\n\ndf[\"Spam\"] = df[\"rawContent\"].progress_apply(predict_spam)\n\n\ndf.to_csv(\"spam.csv\", index=False)\ndf\nprint(\"Spam analysis completed!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:26:22.833336Z","iopub.execute_input":"2023-12-28T15:26:22.833662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_metric\nimport pandas as pd\nfrom transformers import pipeline\nfrom scipy.special import expit\n\n# Load the model and tokenizer\nmodel_name = f\"cardiffnlp/tweet-topic-21-multi\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\nfrom tqdm import tqdm\ntqdm.pandas()\n# pipe = pipeline(\"text-classification\", model=\"csariyildiz/enron_spam_bert_base\")\n\n# labels = {0: \"Not spam\", 1: \"Spam\"}\nclass_mapping = model.config.id2label\nlabels = class_mapping\n\ndef predict_topic(text):\n    \"\"\"\n    \"\"\"\n    encoded_input = tokenizer(text,  truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n    output = model(**encoded_input)\n    predictions = output.logits.argmax(-1)\n    return labels[predictions.item()]\n\ndf[\"Topic\"] = df[\"rawContent\"].progress_apply(predict_topic)\n\n\n# Save the results to a new CSV file\ndf.to_csv(\"topic.csv\", index=False)\ndf\nprint(\"Topic analysis completed!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:52:46.564387Z","iopub.execute_input":"2023-12-28T10:52:46.564811Z","iopub.status.idle":"2023-12-28T10:53:32.882852Z","shell.execute_reply.started":"2023-12-28T10:52:46.564783Z","shell.execute_reply":"2023-12-28T10:53:32.881953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}